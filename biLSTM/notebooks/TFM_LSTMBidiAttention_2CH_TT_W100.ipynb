{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca661a73-de2d-4079-8138-914bab318805",
   "metadata": {
    "id": "ca661a73-de2d-4079-8138-914bab318805"
   },
   "source": [
    "# Deep neural network-based models for predicting mRNA editing in Trachurus trachurus with window width of 100+1+100\n",
    "\n",
    "Bidirectional LSTM with Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f60581-a961-4284-9b0b-3867f3b54213",
   "metadata": {
    "executionInfo": {
     "elapsed": 2495,
     "status": "ok",
     "timestamp": 1657690039600,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "c9f60581-a961-4284-9b0b-3867f3b54213"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, precision_score, cohen_kappa_score, classification_report\n",
    "import seaborn as sns; sns.set()\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b7d71-286c-433d-b5b5-94e41403d218",
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1657690041384,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "7b4b7d71-286c-433d-b5b5-94e41403d218"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# PARAMS\n",
    "########################################\n",
    "fname      = 'ttr_DL_Pad_W100_BALANCED_1_1_CODED2CH.csv'\n",
    "separator_char=';'\n",
    "categories=[['A','G','C','T'],['s','d','h','i','b']]\n",
    "padding=True\n",
    "ptrain     = 0.7\n",
    "trace_level = 1\n",
    "model_name = 'TFM_LSTMBidiAttention_TT_W100'\n",
    "num_lstm_units=256\n",
    "n_epochs=40\n",
    "batch_size=32\n",
    "categories_size=20\n",
    "random_seed=2022\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd49147-7ef8-4a2b-ba75-694d51a94f88",
   "metadata": {
    "id": "1bd49147-7ef8-4a2b-ba75-694d51a94f88",
    "outputId": "eba0a3a5-140a-404c-f883-4f3124dcfbae"
   },
   "source": [
    "We can run this notebook in two environments:\n",
    "+ Googlr Colab Pro (Cloud)\n",
    "+ Jupyter Lab (Locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00b8cf-d29e-429d-a4cc-e05f4416b635",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1657690048200,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "be00b8cf-d29e-429d-a4cc-e05f4416b635",
    "outputId": "8f3677eb-de8e-4a23-dae2-80f591a5c653"
   },
   "outputs": [],
   "source": [
    "#CHECK GOOGLE COLAB\n",
    "GOOGLE_COLAB=False\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  GOOGLE_COLAB=True  \n",
    "  print('Running on CoLab')\n",
    "else:\n",
    "  print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebcbc7-a0de-4a91-aa76-4f422bd2383c",
   "metadata": {
    "id": "26ebcbc7-a0de-4a91-aa76-4f422bd2383c",
    "outputId": "eba0a3a5-140a-404c-f883-4f3124dcfbae"
   },
   "source": [
    "Checking if GPU is available and GPU characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa0226-d138-40dd-bab2-7d0aedec9746",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4843,
     "status": "ok",
     "timestamp": 1657690057394,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "e6fa0226-d138-40dd-bab2-7d0aedec9746",
    "outputId": "f820b273-8ab7-4776-aecf-0afb0d94265c"
   },
   "outputs": [],
   "source": [
    "#CHECK GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print('GPU device not found')\n",
    "else:\n",
    "  print('Num GPUs Available: {}'.format(len(tf.config.list_physical_devices('GPU'))))\n",
    "  print('Found GPU at: {}'.format(device_name))\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "     print('Not connected to a GPU')\n",
    "  else:\n",
    "     print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259c02c-bb23-43d6-899b-f9cbd4ca898d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17372,
     "status": "ok",
     "timestamp": 1657690078416,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "d259c02c-bb23-43d6-899b-f9cbd4ca898d",
    "outputId": "fb727191-8854-4aef-b571-79e0a83d37f9"
   },
   "outputs": [],
   "source": [
    "if padding==True:\n",
    "    categories_size=21\n",
    "\n",
    "if GOOGLE_COLAB==False:\n",
    "    data_dir = '../../data/datasets/ALL_TT/W100'\n",
    "    models_dir = './SAVED_MODELS'\n",
    "\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    #set the path to find RNAEd module\n",
    "    sys.path.insert(0,'/content/drive/MyDrive/ColabNotebooks')    \n",
    "    data_dir  = '/content/drive/MyDrive/DATASETS/ALL_TT/W100'\n",
    "    models_dir= '/content/drive/MyDrive/MODELS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3277a99-0187-4e81-b4e7-a5bb99d7cc27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1657690082697,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "d3277a99-0187-4e81-b4e7-a5bb99d7cc27",
    "outputId": "fb1dcd05-6f2e-4195-ef50-a6d96edefef5"
   },
   "outputs": [],
   "source": [
    "from rnaed import DataGenerator,DataEncoding\n",
    "encoding=DataEncoding(categories,padding=padding,pad_char=\"*\")\n",
    "n_ch,cat=encoding.getChannels()\n",
    "print(\"Number of channels: {} /categories: {}\".format(n_ch,cat))\n",
    "encoding.print_LUT_TupleToInteger()\n",
    "categories_size=encoding.getNumCodes()\n",
    "print(\"Number of codes or categories size: {}\".format(categories_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f58b95-6aea-45de-af97-5f2964dd413a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1657690085843,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "d1f58b95-6aea-45de-af97-5f2964dd413a",
    "outputId": "e3fbef3e-c26f-4fbd-a5c4-09c0d60e3263"
   },
   "outputs": [],
   "source": [
    "#We can save best model and last model\n",
    "best_model = 'best_model_'+model_name+'.h5'\n",
    "last_model =  model_name+'.h5'\n",
    "lastmodelfile = os.path.join(models_dir, last_model)\n",
    "print(\"LAST MODEL FILE: {}\".format(lastmodelfile))\n",
    "bestmodelfile = os.path.join(models_dir, best_model)\n",
    "print(\"BEST MODEL FILE: {}\".format(bestmodelfile))\n",
    "datafile = os.path.join(data_dir, fname)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c001b8d-f491-45da-a667-9d566df08c38",
   "metadata": {
    "id": "8c001b8d-f491-45da-a667-9d566df08c38",
    "outputId": "dca7aef9-a604-426f-ef3d-725b81ca9baa"
   },
   "source": [
    "We read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206aec14-c210-499a-9601-09d1443cd01e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2170,
     "status": "ok",
     "timestamp": 1657690091904,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "206aec14-c210-499a-9601-09d1443cd01e",
    "outputId": "cffb0dec-90e2-4cea-c6dc-4e45c8d19896"
   },
   "outputs": [],
   "source": [
    "print(\"DATASET: {}\".format(datafile))\n",
    "data = pd.read_csv(datafile,sep=separator_char)\n",
    "print(\"shape dataraw={}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49530e4f-caa7-4b65-b386-21e272945a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4689c11-867e-44b1-bb6c-8be3e6628d34",
   "metadata": {
    "id": "d4689c11-867e-44b1-bb6c-8be3e6628d34",
    "outputId": "c6394162-7647-4e1e-a983-2aa4df3a5242"
   },
   "source": [
    "We will divide the data into: train, validation and test.\n",
    "The three datastes should be well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e9343-353e-4b66-921e-2e2d0966bf5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1657690100047,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "ae0e9343-353e-4b66-921e-2e2d0966bf5c",
    "outputId": "7b995578-88c9-4443-9344-7f378e7b042e"
   },
   "outputs": [],
   "source": [
    "# Train and Validation+Test\n",
    "data_train, data_val_test, data_y_train, data_y_val_test = train_test_split(data, data['EDITING'], test_size=1-ptrain, random_state=random_seed)\n",
    "#Validation and test: 0.5/0.5\n",
    "data_val, data_test, data_y_val, data_y_test = train_test_split(data_val_test, data_y_val_test, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "print(\"data_train:{} data_y_train:{}\".format(data_train.shape,data_y_train.shape))\n",
    "print(\"data_val: {} data_y_val: {}\".format(data_val.shape,data_y_val.shape))\n",
    "print(\"data_test: {} data_y_test: {}\".format(data_test.shape,data_y_test.shape))\n",
    "print(\"TRAIN LABELS:\")\n",
    "print(data_y_train.value_counts())\n",
    "print(\"VALIDATION LABELS:\")\n",
    "print(data_y_val.value_counts())\n",
    "print(\"TEST LABELS:\")\n",
    "print(data_y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da206f4-e9f8-4b63-a2c3-eb8488556381",
   "metadata": {
    "id": "6da206f4-e9f8-4b63-a2c3-eb8488556381"
   },
   "source": [
    "We instantiate 3 DataGenerator objects that convert from integer to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f208a-c441-4bb4-b300-642edd73d955",
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1657690110100,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "801f208a-c441-4bb4-b300-642edd73d955"
   },
   "outputs": [],
   "source": [
    "#DataGenerator converts on the fly from raw data to one-hot\n",
    "num_nucleosides = data_train.iloc[:,3:].shape[1]\n",
    "num_tokens = categories_size\n",
    "\n",
    "training_generator   = DataGenerator(data_train.iloc[:,3:], data_y_train, batch_size=batch_size, seq_size=num_nucleosides, categories_size=categories_size, shuffle=True)\n",
    "validation_generator = DataGenerator(  data_val.iloc[:,3:], data_y_val,   batch_size=batch_size, seq_size=num_nucleosides, categories_size=categories_size, shuffle=True)\n",
    "test_generator       = DataGenerator( data_test.iloc[:,3:], data_y_test,  batch_size=1,seq_size=num_nucleosides, categories_size=categories_size, shuffle=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddddf12b-b24f-4b5e-9540-6e49d380ff2d",
   "metadata": {
    "id": "ddddf12b-b24f-4b5e-9540-6e49d380ff2d",
    "outputId": "eb581962-8561-491c-822c-04e260bcf0cd"
   },
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b561c-65d2-43a4-8ee2-dd1d7148d93e",
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1657690112984,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "204b561c-65d2-43a4-8ee2-dd1d7148d93e"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "\n",
    "class attention(Layer):\n",
    "    ''' heredamos de la clase layer '''\n",
    "    def __init__(self):\n",
    "        super(attention,self).__init__()\n",
    "    \n",
    "    #En el método build definimos los pesos\n",
    "    def build(self, input_shape):\n",
    "        # Define the shape of the weights and bias in this layer\n",
    "        # The layer has just 1 lonely neuron\n",
    "        \n",
    "        # For convenience sake, add a couple of properties\n",
    "        self.num_dim_pernucleoside = input_shape[-1] ## 512 dimension del vector de contexto.\n",
    "        self.nucleosides_persequence = input_shape[-2]  ## 101 número de timesteps de la secuencia\n",
    "        num_units = 1\n",
    "        \n",
    "        \n",
    "        #Weights shape=(512,1), recordemos que la red neuronal capa oculta tiene un peso por dimensión.\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(self.num_dim_pernucleoside,num_units),\n",
    "                               initializer=\"normal\")\n",
    "        #bias  shape=(101,1), hay un bias por cada timestep, palabra o nucleótido.\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(self.nucleosides_persequence,num_units),\n",
    "                               initializer=\"zeros\")\n",
    "        super(attention,self).build(input_shape)\n",
    "    \n",
    "    #en el método call definimos la lógica\n",
    "    #esta es la implementación clásica\n",
    "    def call_classic(self, x):\n",
    "        # x is the input tensor of 2 x num_units = 512 dimensions\n",
    "        \"\"\" We multiply the inputs ‘x’ of shape (101,512) by the layer weights ‘w’ \n",
    "        of shape (512 , 1) and obtain a (101,1) values (future attention weights). We add the bias (101,1) \n",
    "        and pass the output through any activation layer to form a neural network. So we now have 101 * 1 values and \n",
    "        We take a softmax of these values. Softmax squashes these into values in the \n",
    "        range between 0, and 1 whose sum is 1. These are the 101 attention weights. \n",
    "        We multiply each attention weight by the respective nucleoside hidden state and sum up and we are done. \n",
    "        We now have the ‘attention adjusted output’ state ready to be fed to the next dense layer for classification.\"\"\"\n",
    "        \n",
    "        #e = K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)  # Necesario en algunos frameworks\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b) #Red neuronal densa de una neurona con una matriz de pesos W y un vector de bias\n",
    "        a = K.softmax(e, axis=1) #hacemos softmax para normalizar y que los pesos sumen 1.\n",
    "        # Multiplicamos cada hidden state por cada peso (101,512)*(101,1)=(101,512). \n",
    "        # No es matricial, sino componente a componente \n",
    "        output = x*a \n",
    "        #Sumamos los 101 hidden states y se obtiene un hidden state suma de dimensión (101,512)\n",
    "        #También se retornan los pesos a (101,1)\n",
    "        return a, K.sum(output, axis=1)\n",
    "  \n",
    "    #esta implementación es más robusta\n",
    "    def call(self, x):\n",
    "        \"\"\" Es lo mismo de antes pero más robusto a distintos frameworks\"\"\"\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b) # dimensiones (101,512)(512,1)+(101,1)=(101,1)\n",
    "        e = Flatten()(e) #(?,101)\n",
    "        a = Activation('softmax')(e) #(?,101)\n",
    "        # Repite 512 veces los 101 pesos (?,101) = (?,512,101)\n",
    "        temp = RepeatVector(self.num_dim_pernucleoside)(a)\n",
    "        #Permuta (?,512,101) por (?,101,512) para poder multiplicar componente a \n",
    "        #componente después\n",
    "        temp = Permute([2,1])(temp) \n",
    "        # Multiplicamnos por cada peso todas las componentes de todos los hidden states\n",
    "        # hidden state X=(101,512) pesos=temp=(101,512)\n",
    "        # el truco aquí es que cada fila de pesos es una repetición de 512 pesos iguales.\n",
    "        output = Multiply()([x,temp])\n",
    "        #Finalmente sumamos todas las filas y obtenemos así el hidden state ponderado\n",
    "        output = Lambda(lambda values: K.sum(values, axis=1))(output)\n",
    "        #Retornamos los pesos de atención y la suma de los hidden states.\n",
    "        return a, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef2548-0324-428e-9211-2f524ed4cbbe",
   "metadata": {
    "id": "77ef2548-0324-428e-9211-2f524ed4cbbe",
    "outputId": "eb581962-8561-491c-822c-04e260bcf0cd"
   },
   "source": [
    "## Model defined from the scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b34b7-ddaa-465a-8f3b-69e9e321fd2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1657690118049,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "857b34b7-ddaa-465a-8f3b-69e9e321fd2c",
    "outputId": "b96f1089-2404-4ca3-b159-6ae424faec4a"
   },
   "outputs": [],
   "source": [
    "#MODELOS REDES NEURONALES LSTM CON CAPAS DE ATENCIÓN\n",
    "# Import the libraries required in this example:\n",
    "print(\"Number of units={}\".format(num_lstm_units))\n",
    "#Definimos la estructura con el Functional model\n",
    "inputs = keras.Input(shape=(num_nucleosides,num_tokens), name=\"INPUTS\")\n",
    "lstm_out   = layers.Bidirectional(layers.LSTM(num_lstm_units,return_sequences=True), name=\"LSTM_BI\")(inputs)\n",
    "dropout= layers.Dropout(0.2)(lstm_out)\n",
    "\n",
    "#===============================\n",
    "#METHOD 1: using a custom layer:\n",
    "#===============================\n",
    "#La salida de la capa bidireccional será de 1 batch=None numero de secuencias, \n",
    "#de 101 nucleosidos(timesteps=50+1+50) de 2 x número_unidades=2*256=512\n",
    "#Es decir (None,101,512)\n",
    "#---------uncomment here--------------------\n",
    "#a ,att_d = attention()(dropout)\n",
    "#-----------------------------\n",
    "#La capa de atención debe retornarnos un peso para cada hidden state \n",
    "#correspondiente a cada elemento de la secuencia o timestep\n",
    "#es decir, nos debe dar un peso por cada nucleósido, es decir, nos debe dar (101,1)\n",
    "#Como son pesos probabilisticos deben sumar 1.\n",
    "#Pero realmente no queremos esos pesos, sino la suma de los 101 hidden states \n",
    "#de dimensión 512 ponderados por esos pesos que es lo que conforma el verdadero contexto, \n",
    "# y que tendrá dimensión (None,1,512).\n",
    "#Esta salida es lo que se llama el \"attention adjusted output state\".\n",
    "#Para ello, nuestra capa de atención debe entrenar (101,1) pesos, ya que debemos \n",
    "#entrenar un peso por cada dimensión del espacio vectorial del contexto.\n",
    "#Pero ojo, esos no son los pesos de la red neuronal de la capa de atención, porque si nuestra\n",
    "#red neuronal de atención tuviera 101 pesos, serían posicionales y deben ser calculados por el \n",
    "#valor semántico de los nucleótidos (si fueran palabras por su significado, no por su posición)\n",
    "\n",
    "#Nuestra red neuronal de atención debe atender al \"significado\" de las palabras, es decir,\n",
    "#a la codificación de cada nucleótido en el vector de estados \n",
    "#de la LSTM que tiene dimensión 512. Por lo tanto el número de pesos de la  red de atención \n",
    "# es de (512,1). Son los pesos de las 512 conexiones de la neurona de esta capa.\n",
    "\n",
    "#Durante el entrenamiento multiplicaremos matricialmente todos los nucleótidos de la \n",
    "#secuencia (101), con su codificación LSTMbidi(512), por los pesos de la capa de atención(512) y eso \n",
    "#nos dará los 101 pesos de atención:\n",
    "#(101,512) x (512,1) = (101,1) los pesos de atención\n",
    "#(512,1) son los pesos de la capa.\n",
    "\n",
    "#Ahora entendemos por qué los pesos de atención no son constantes\n",
    "#sino que para cada secuencia cambian:\n",
    "#En una red ya entrenada:\n",
    "#  (101,512)[variable] x (512,1)[constante] = (101,1)[variable]\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "#===============================\n",
    "#METHOD 2: using regular layers:\n",
    "#===============================\n",
    "\n",
    "#---------uncomment here--------------------\n",
    "e=Dense(1, activation='tanh')(dropout) #Capa de atención\n",
    "e=Flatten()(e)\n",
    "a=Activation('softmax')(e) #Softmax para que sumen 1 los pesos de atención.\n",
    "temp=RepeatVector(2*num_lstm_units)(a)\n",
    "temp=Permute([2, 1])(temp)\n",
    "# multiply weight with LSTM layer o/p\n",
    "output = Multiply()([dropout, temp])\n",
    "# Get the attention adjusted output state by adding up\n",
    "att = Lambda(lambda values: K.sum(values, axis=1))(output)\n",
    "#-----------------------------\n",
    "\n",
    "#===============================================================\n",
    "outputs= layers.Dense(1, activation='sigmoid', name=\"OUTPUT\")(att)\n",
    "#Creamos el modelo\n",
    "model_from_scratch  = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "#Mostramos el modelo\n",
    "print(model_from_scratch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc47876-f37d-49b9-8927-208034317df9",
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1657690122984,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "ddc47876-f37d-49b9-8927-208034317df9"
   },
   "outputs": [],
   "source": [
    "#Compilation reset all weights\n",
    "model_from_scratch.compile(optimizer=keras.optimizers.Adam(),\n",
    "                           loss     =keras.losses.BinaryCrossentropy(),\n",
    "                           metrics  =[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "model=model_from_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9WyvcKhMJSEE",
   "metadata": {
    "id": "9WyvcKhMJSEE"
   },
   "source": [
    "Recover last model, best model or generate a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c51c7-f1ee-489b-b306-fbf948a07a51",
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1657690127618,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "643c51c7-f1ee-489b-b306-fbf948a07a51"
   },
   "outputs": [],
   "source": [
    "#Load the trained model from disk\n",
    "import os.path\n",
    "\n",
    "best_model_accuracy =0\n",
    "last_model_accuracy =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3IuCH91HwwUR",
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1657690131222,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "3IuCH91HwwUR"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(bestmodelfile):\n",
    "    model = tf.keras.models.load_model(bestmodelfile)\n",
    "    print(\"Testing best model file: {}\".format(bestmodelfile))\n",
    "    results = model.evaluate(validation_generator,verbose=1)\n",
    "    best_model_accuracy = results[1]\n",
    "    print(\"best model accuracy: {}\".format(best_model_accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rxiGXKZhwbS-",
   "metadata": {
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1657690134147,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "rxiGXKZhwbS-"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(lastmodelfile):\n",
    "    model = tf.keras.models.load_model(lastmodelfile)\n",
    "    print(\"Testing last complete model file: {}\".format(lastmodelfile))\n",
    "    results = model.evaluate(validation_generator,verbose=1)\n",
    "    last_model_accuracy = results[1]\n",
    "    print(\"last model accuracy: {}\".format(last_model_accuracy))           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58jDsR4BwkN-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1657690147480,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "58jDsR4BwkN-",
    "outputId": "aa03b3b8-db71-4bed-b880-bfa2bf64a869"
   },
   "outputs": [],
   "source": [
    "if best_model_accuracy >= last_model_accuracy and best_model_accuracy != 0:\n",
    "   model = tf.keras.models.load_model(bestmodelfile)\n",
    "   print(\"Selected best model saved: {}\".format(bestmodelfile))\n",
    "else:\n",
    "  if last_model_accuracy > best_model_accuracy:\n",
    "     print(\"Selected last model saved: {}\".format(lastmodelfile))\n",
    "  else:\n",
    "     print(\"Selected new untrained model\")\n",
    "\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b1c7b-7c45-4483-88fc-e60a012edba0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1657690152096,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "644b1c7b-7c45-4483-88fc-e60a012edba0",
    "outputId": "ff9accf9-79b8-4c96-9c55-092cc94b1190"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d28828-8ee5-4bc6-8b97-1e06ab60c519",
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1657690158967,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "84d28828-8ee5-4bc6-8b97-1e06ab60c519"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(bestmodelfile, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,\n",
    "                             save_best_only=True, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "\n",
    "callback=EarlyStopping(monitor='val_loss', \n",
    "                       min_delta=0, \n",
    "                       patience=3, \n",
    "                       verbose=1, \n",
    "                       mode='auto',\n",
    "                       baseline=None, \n",
    "                       restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22345410-c762-42e4-9767-5ef8b1edb003",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 507639,
     "status": "ok",
     "timestamp": 1657691859323,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "22345410-c762-42e4-9767-5ef8b1edb003",
    "outputId": "a283105d-695f-44e0-a027-41bd9e8c1c5f"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):#Use GPU if available\n",
    "    history=model.fit(training_generator,epochs=n_epochs,\n",
    "                      validation_data=validation_generator,\n",
    "                      callbacks=[checkpoint,callback],verbose=trace_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edd824-ea63-46fa-a917-5e41dbd3422c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1657692088490,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "c8edd824-ea63-46fa-a917-5e41dbd3422c",
    "outputId": "19a3e231-de9e-41de-8416-67ba7162ce9c"
   },
   "outputs": [],
   "source": [
    "#We always save the last model.\n",
    "#Last model can be triggered by early stopping\n",
    "n_epochs_trained = len(history.history['loss'])\n",
    "print(\"Trained epochs: {} of {}\".format(n_epochs_trained,n_epochs))\n",
    "model.save(lastmodelfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb710-78e7-4734-b41f-eccd0a9ff589",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1657692094653,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "634fb710-78e7-4734-b41f-eccd0a9ff589",
    "outputId": "197d1ee1-baf4-452e-e2fd-ea914bf29e08"
   },
   "outputs": [],
   "source": [
    "#PLOT ACCURACY AND LOSS\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366e2cf-105b-4007-8732-9c3f330f9cb2",
   "metadata": {
    "id": "c366e2cf-105b-4007-8732-9c3f330f9cb2",
    "outputId": "c72777c6-5a20-481f-c89e-89ed00121599"
   },
   "source": [
    "We recover the best model saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657a2d3-548a-4475-a171-831406ed1140",
   "metadata": {
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1657692105187,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "d657a2d3-548a-4475-a171-831406ed1140"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(bestmodelfile):\n",
    "    model = tf.keras.models.load_model(bestmodelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11909c-fe48-433d-a1ab-b038b301bc16",
   "metadata": {
    "id": "4a11909c-fe48-433d-a1ab-b038b301bc16",
    "outputId": "c72777c6-5a20-481f-c89e-89ed00121599"
   },
   "source": [
    "We evaluate the best model on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae3e40-6872-49cd-95c2-91b624ee4193",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29351,
     "status": "ok",
     "timestamp": 1657692137143,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "4bae3e40-6872-49cd-95c2-91b624ee4193",
    "outputId": "2e439f29-2f01-41c0-cf53-27f2321299f5"
   },
   "outputs": [],
   "source": [
    "#EVALUATE VALIDATION DATASET\n",
    "print(\"Evaluate models on validation data\")\n",
    "results_model = model.evaluate(validation_generator,verbose=trace_level)\n",
    "print ('Accuracy on validation data:',round(results_model[1],3))\n",
    "print ('Loss on validation data:',round(results_model[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81704c88-897a-4f89-b1f5-80f6a5f3d364",
   "metadata": {
    "id": "81704c88-897a-4f89-b1f5-80f6a5f3d364",
    "outputId": "205c012b-84d2-4f51-c96a-398417f7e61f"
   },
   "source": [
    "We make predictions on test data, never used during training nor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7abf2c-e423-485d-a543-06f4743971c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95697,
     "status": "ok",
     "timestamp": 1657692238428,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "fb7abf2c-e423-485d-a543-06f4743971c7",
    "outputId": "a4a8d8a3-296e-44b0-fc13-b0fb544c95af"
   },
   "outputs": [],
   "source": [
    "#PREDICTIONS\n",
    "print(\"Make predictions on test data\")\n",
    "model_prediction = model.predict(test_generator,verbose=trace_level)\n",
    "model_prediction_binary = (model_prediction > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08289e1-32e4-4290-82c7-b87718f230a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1657692567041,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "d08289e1-32e4-4290-82c7-b87718f230a9",
    "outputId": "e500bb5e-b0d8-4ff7-df94-488785c28905"
   },
   "outputs": [],
   "source": [
    "print(data_test.shape)\n",
    "print(data_y_test.shape)\n",
    "print(model_prediction.shape)\n",
    "print(model_prediction_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9296b0f-efc6-4133-aaff-949a4159e5f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1657692570143,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "a9296b0f-efc6-4133-aaff-949a4159e5f7",
    "outputId": "8c4bcabe-55b7-4a93-d984-00c2b8a16123"
   },
   "outputs": [],
   "source": [
    "#METRICS QUALITY CLASSIFICATION\n",
    "print(\"MODEL \"+model_name+\"\\n---------------------------------\")\n",
    "kappa = cohen_kappa_score(data_y_test, model_prediction_binary)\n",
    "print ('Kappa:',round(kappa,3))\n",
    "print(classification_report(data_y_test, model_prediction_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f01e9-daf3-43f6-bd2f-d1fee30059cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1657692576633,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "686f01e9-daf3-43f6-bd2f-d1fee30059cb",
    "outputId": "db491308-f47a-4b04-db44-cb786b7ad533"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, cohen_kappa_score, classification_report\n",
    "import seaborn as sns; sns.set()\n",
    "# PLOT CONFUSION MATRIX\n",
    "# Tutorial: https://www.stackvidhya.com/plot-confusion-matrix-in-python-and-why/\n",
    "plt.figure()\n",
    "\n",
    "cm = confusion_matrix(data_y_test,model_prediction_binary)\n",
    "\n",
    "group_names = ['TN','FP','FN','TP']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "ax.set_title('RNA-Editing Confusion Matrix \\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values '+ model_name)\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "#ax.xaxis.set_ticklabels(['False','True'])\n",
    "#ax.yaxis.set_ticklabels(['False','True'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95327601-ffc7-4a46-b204-57c81392e711",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1657692685589,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "c1ff605a-c7fd-4160-ba29-a2e88cd1829e",
    "outputId": "a58b14c5-9363-4ea4-a0d3-9e54d603ec1e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "auc = roc_auc_score(data_y_test, model_prediction)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(data_y_test, model_prediction)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cbaa05-33dc-4c0f-8b7a-93f34a0ff4af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1657692685589,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "c1ff605a-c7fd-4160-ba29-a2e88cd1829e",
    "outputId": "a58b14c5-9363-4ea4-a0d3-9e54d603ec1e"
   },
   "source": [
    "# RESULTS INSIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2790fe1-48b6-4412-8903-67b665898361",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = data_test\n",
    "if 'RESULT_TYPE' not in results_data.columns:\n",
    "    #insert column at position 3\n",
    "    results_data.insert(3,\"RESULT_TYPE\", None)\n",
    "    results_data.insert(4,\"PROB_PRED\",model_prediction)\n",
    "else:\n",
    "    print(\"RESULT_TYPE already exists in the dataframe\")\n",
    "\n",
    "results_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d62286-5485-4aea-9ae2-f726bd4ef33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_index=results_data.columns.get_loc('RESULT_TYPE')\n",
    "i=0\n",
    "for result in model_prediction_binary:\n",
    "    #print(\"Comparing result={} with data_y_test={}\".format(result[0],data_y_test.iloc[i]))\n",
    "    if   result[0]==0 and data_y_test.iloc[i]==0:\n",
    "       typeRes =\"TN\"\n",
    "    elif result[0]==0 and data_y_test.iloc[i]==1:\n",
    "       typeRes=\"FN\"\n",
    "    elif result[0]==1 and data_y_test.iloc[i]==0:\n",
    "       typeRes=\"FP\"\n",
    "    elif result[0]==1 and data_y_test.iloc[i]==1:\n",
    "       typeRes=\"TP\"\n",
    "    results_data.iloc[i, column_index]=typeRes\n",
    "    i+=1\n",
    "    \n",
    "results_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8a953-83d9-4f03-8e77-167d6be65f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results into a file\n",
    "report_dir=\"./report\"\n",
    "results_csv_file  =model_name + \"_Results.csv\"\n",
    "results_excel_file=model_name + \"_Results.xlsx\"\n",
    "results_data.to_csv(os.path.join(report_dir,results_csv_file))\n",
    "results_data.to_excel(os.path.join(report_dir,results_excel_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef227ac2-1811-4f0f-85b5-1800e691f3fa",
   "metadata": {},
   "source": [
    "Now, we are going to find the record with highest probability and category TP (True Positive) as a good model of TP data,\n",
    "and alternatively, the best representative of TN, using the lowest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ed665-9b54-4347-9e4c-bb1cd73c3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_TP=results_data.loc[results_data['RESULT_TYPE'] == 'TP']\n",
    "prototype_of_TP_id=subset_TP['PROB_PRED'].idxmax()\n",
    "print(\"rowid best TP = {}\".format(prototype_of_TP_id))\n",
    "print(results_data.loc[prototype_of_TP_id,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe98932-6099-4898-8859-167b69bb60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_TN=results_data.loc[results_data['RESULT_TYPE'] == 'TN']\n",
    "prototype_of_TN_id=subset_TN['PROB_PRED'].idxmin()\n",
    "print(\"rowid best TN = {}\".format(prototype_of_TN_id))\n",
    "print(results_data.loc[prototype_of_TN_id,])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "TFM_LSTMBidiAttention_2CH_MM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-lsr] *",
   "language": "python",
   "name": "conda-env-tensorflow-lsr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
