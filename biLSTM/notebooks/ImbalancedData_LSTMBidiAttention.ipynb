{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca661a73-de2d-4079-8138-914bab318805",
   "metadata": {
    "id": "ca661a73-de2d-4079-8138-914bab318805",
    "tags": []
   },
   "source": [
    "# Deep neural network-based models for predicting mRNA editing with highly imbalanced data\n",
    "\n",
    "Bidirectional LSTM with Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f60581-a961-4284-9b0b-3867f3b54213",
   "metadata": {
    "id": "c9f60581-a961-4284-9b0b-3867f3b54213"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, precision_score, cohen_kappa_score, classification_report\n",
    "import seaborn as sns; sns.set()\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b7d71-286c-433d-b5b5-94e41403d218",
   "metadata": {
    "id": "8c077d3a-3edc-4341-b1e6-59a67fe44442"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# PARAMS\n",
    "########################################\n",
    "fname      = 'hg38_IMBALANCED.csv'\n",
    "separator_char=';'\n",
    "categories=[['A','G','C','T'],['s','d','h','i','b']]\n",
    "padding=True\n",
    "sample_frac = 0.1\n",
    "ptrain     = 0.7\n",
    "trace_level = 1\n",
    "model_name = 'Imbalanced_LSTMBidiAttention'\n",
    "num_lstm_units=256\n",
    "n_epochs=40\n",
    "#batch_size=32\n",
    "batch_size=128\n",
    "categories_size=20\n",
    "random_seed=2022\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd49147-7ef8-4a2b-ba75-694d51a94f88",
   "metadata": {
    "id": "1bd49147-7ef8-4a2b-ba75-694d51a94f88",
    "outputId": "eba0a3a5-140a-404c-f883-4f3124dcfbae"
   },
   "source": [
    "We can run this notebook in two environments:\n",
    "+ Googlr Colab Pro (Cloud)\n",
    "+ Jupyter Lab (Locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00b8cf-d29e-429d-a4cc-e05f4416b635",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1653155694898,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "be00b8cf-d29e-429d-a4cc-e05f4416b635",
    "outputId": "ade3fab1-7488-400e-f83e-359d33a23f14"
   },
   "outputs": [],
   "source": [
    "#CHECK GOOGLE COLAB\n",
    "GOOGLE_COLAB=False\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  GOOGLE_COLAB=True  \n",
    "  print('Running on CoLab')\n",
    "else:\n",
    "  print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebcbc7-a0de-4a91-aa76-4f422bd2383c",
   "metadata": {
    "id": "26ebcbc7-a0de-4a91-aa76-4f422bd2383c",
    "outputId": "eba0a3a5-140a-404c-f883-4f3124dcfbae"
   },
   "source": [
    "Checking if GPU is available and GPU characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa0226-d138-40dd-bab2-7d0aedec9746",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1653155695712,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "e6fa0226-d138-40dd-bab2-7d0aedec9746",
    "outputId": "c03b8850-61bb-4558-88e3-90b0f25a0604"
   },
   "outputs": [],
   "source": [
    "#CHECK GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print('GPU device not found')\n",
    "else:\n",
    "  print('Num GPUs Available: {}'.format(len(tf.config.list_physical_devices('GPU'))))\n",
    "  print('Found GPU at: {}'.format(device_name))\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "     print('Not connected to a GPU')\n",
    "  else:\n",
    "     print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259c02c-bb23-43d6-899b-f9cbd4ca898d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3957,
     "status": "ok",
     "timestamp": 1653155699660,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "0932c47c-8f33-4656-9214-c0b6fce1bf64",
    "outputId": "78bf807b-8b86-4f10-f849-65e790e0abab"
   },
   "outputs": [],
   "source": [
    "if padding==True:\n",
    "    categories_size=21\n",
    "\n",
    "if GOOGLE_COLAB==False:\n",
    "    data_dir = '../../data/datasets/RAND1000/W50'\n",
    "    models_dir = './SAVED_MODELS'\n",
    "\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    import sys\n",
    "    #set the path to find RNAEd module\n",
    "    sys.path.insert(0,'/content/drive/MyDrive/ColabNotebooks')    \n",
    "    data_dir  = '/content/drive/MyDrive/DATASETS/RAND1000/W50'\n",
    "    models_dir= '/content/drive/MyDrive/MODELS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3277a99-0187-4e81-b4e7-a5bb99d7cc27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3957,
     "status": "ok",
     "timestamp": 1653155699660,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "0932c47c-8f33-4656-9214-c0b6fce1bf64",
    "outputId": "78bf807b-8b86-4f10-f849-65e790e0abab"
   },
   "outputs": [],
   "source": [
    "from rnaed import DataGenerator,DataEncoding\n",
    "encoding=DataEncoding(categories,padding=padding,pad_char=\"*\")\n",
    "n_ch,cat=encoding.getChannels()\n",
    "print(\"Number of channels: {} /categories: {}\".format(n_ch,cat))\n",
    "encoding.print_LUT_TupleToInteger()\n",
    "categories_size=encoding.getNumCodes()\n",
    "print(\"Number of codes or categories size: {}\".format(categories_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f58b95-6aea-45de-af97-5f2964dd413a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3957,
     "status": "ok",
     "timestamp": 1653155699660,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "0932c47c-8f33-4656-9214-c0b6fce1bf64",
    "outputId": "78bf807b-8b86-4f10-f849-65e790e0abab"
   },
   "outputs": [],
   "source": [
    "#We can save best model and last model\n",
    "best_model = 'best_model_'+model_name+'.h5'\n",
    "last_model =  model_name+'.h5'\n",
    "lastmodelfile = os.path.join(models_dir, last_model)\n",
    "print(\"LAST MODEL FILE: {}\".format(lastmodelfile))\n",
    "bestmodelfile = os.path.join(models_dir, best_model)\n",
    "print(\"BEST MODEL FILE: {}\".format(bestmodelfile))\n",
    "datafile = os.path.join(data_dir, fname)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c001b8d-f491-45da-a667-9d566df08c38",
   "metadata": {
    "id": "8c001b8d-f491-45da-a667-9d566df08c38",
    "outputId": "dca7aef9-a604-426f-ef3d-725b81ca9baa"
   },
   "source": [
    "We read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206aec14-c210-499a-9601-09d1443cd01e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3484,
     "status": "ok",
     "timestamp": 1653155703139,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "206aec14-c210-499a-9601-09d1443cd01e",
    "outputId": "c4e8b25c-c946-41b2-d5ad-d6b3a82208b8"
   },
   "outputs": [],
   "source": [
    "print(\"DATASET: {}\".format(datafile))\n",
    "data_all = pd.read_csv(datafile,sep=separator_char)\n",
    "print(data_all.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1942e5-891d-40f3-ab8e-552c33c92877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape data_all={}\".format(data_all.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f66a07-532a-49cf-98e1-dca0ae88fc50",
   "metadata": {},
   "source": [
    "We sample a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe854728-1178-49a3-ae59-a43158b0367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.sample(frac=sample_frac)\n",
    "print(\"shape data={}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c59ad-0847-4459-9cad-d8967d7b53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(data['EDITING'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033ddf7-1535-48d7-958b-ae7cf0c353f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28bf26-ae76-414e-b2b0-9e081f40f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation+Test\n",
    "data_train, data_val_test, data_y_train, data_y_val_test = train_test_split(data, data['EDITING'], test_size=1-ptrain, random_state=random_seed)\n",
    "#Validation and test: 0.5/0.5\n",
    "data_val, data_test, data_y_val, data_y_test = train_test_split(data_val_test, data_y_val_test, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "print(\"data_train:{} data_y_train:{}\".format(data_train.shape,data_y_train.shape))\n",
    "print(\"data_val: {} data_y_val: {}\".format(data_val.shape,data_y_val.shape))\n",
    "print(\"data_test: {} data_y_test: {}\".format(data_test.shape,data_y_test.shape))\n",
    "print(\"TRAIN LABELS:\")\n",
    "print(data_y_train.value_counts())\n",
    "print(\"VALIDATION LABELS:\")\n",
    "print(data_y_val.value_counts())\n",
    "print(\"TEST LABELS:\")\n",
    "print(data_y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4689c11-867e-44b1-bb6c-8be3e6628d34",
   "metadata": {
    "id": "d4689c11-867e-44b1-bb6c-8be3e6628d34",
    "outputId": "c6394162-7647-4e1e-a983-2aa4df3a5242"
   },
   "source": [
    "We will divide the data into: train, validation and test.\n",
    "The three datastes should be well balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da206f4-e9f8-4b63-a2c3-eb8488556381",
   "metadata": {
    "id": "6da206f4-e9f8-4b63-a2c3-eb8488556381"
   },
   "source": [
    "We instantiate 3 DataGenerator objects that convert from integer to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f208a-c441-4bb4-b300-642edd73d955",
   "metadata": {
    "id": "801f208a-c441-4bb4-b300-642edd73d955"
   },
   "outputs": [],
   "source": [
    "#DataGenerator converts on the fly from raw data to one-hot\n",
    "#DataGenerator converts on the fly from raw data to one-hot\n",
    "num_nucleosides = data_train.iloc[:,3:].shape[1]\n",
    "num_tokens = categories_size\n",
    "\n",
    "training_generator   = DataGenerator(data_train.iloc[:,3:], data_y_train, batch_size=batch_size, seq_size=num_nucleosides, categories_size=categories_size, shuffle=True)\n",
    "validation_generator = DataGenerator(  data_val.iloc[:,3:], data_y_val,   batch_size=batch_size, seq_size=num_nucleosides, categories_size=categories_size, shuffle=True)\n",
    "test_generator       = DataGenerator( data_test.iloc[:,3:], data_y_test,  batch_size=1,seq_size=num_nucleosides, categories_size=categories_size, shuffle=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef2548-0324-428e-9211-2f524ed4cbbe",
   "metadata": {
    "id": "77ef2548-0324-428e-9211-2f524ed4cbbe",
    "outputId": "eb581962-8561-491c-822c-04e260bcf0cd"
   },
   "source": [
    "## Model defined from the scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b34b7-ddaa-465a-8f3b-69e9e321fd2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1653155704288,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "857b34b7-ddaa-465a-8f3b-69e9e321fd2c",
    "outputId": "350bb811-0298-4795-dc7c-1ccd23287cd4"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "\n",
    "#MODELOS REDES NEURONALES LSTM CON CAPAS DE ATENCIÓN\n",
    "# Import the libraries required in this example:\n",
    "print(\"Number of units={}\".format(num_lstm_units))\n",
    "#Definimos la estructura con el Functional model\n",
    "inputs = keras.Input(shape=(num_nucleosides,num_tokens), name=\"INPUTS\")\n",
    "lstm_out   = layers.Bidirectional(layers.LSTM(num_lstm_units,return_sequences=True), name=\"LSTM_BI\")(inputs)\n",
    "dropout= layers.Dropout(0.2)(lstm_out)\n",
    "\n",
    "#===============================\n",
    "#METHOD 1: using a custom layer:\n",
    "#===============================\n",
    "#La salida de la capa bidireccional será de 1 batch=None numero de secuencias, \n",
    "#de 101 nucleosidos(timesteps=50+1+50) de 2 x número_unidades=2*256=512\n",
    "#Es decir (None,101,512)\n",
    "#---------uncomment here--------------------\n",
    "#a ,att_d = attention()(dropout)\n",
    "#-----------------------------\n",
    "#La capa de atención debe retornarnos un peso para cada hidden state \n",
    "#correspondiente a cada elemento de la secuencia o timestep\n",
    "#es decir, nos debe dar un peso por cada nucleósido, es decir, nos debe dar (101,1)\n",
    "#Como son pesos probabilisticos deben sumar 1.\n",
    "#Pero realmente no queremos esos pesos, sino la suma de los 101 hidden states \n",
    "#de dimensión 512 ponderados por esos pesos que es lo que conforma el verdadero contexto, \n",
    "# y que tendrá dimensión (None,1,512).\n",
    "#Esta salida es lo que se llama el \"attention adjusted output state\".\n",
    "#Para ello, nuestra capa de atención debe entrenar (101,1) pesos, ya que debemos \n",
    "#entrenar un peso por cada dimensión del espacio vectorial del contexto.\n",
    "#Pero ojo, esos no son los pesos de la red neuronal de la capa de atención, porque si nuestra\n",
    "#red neuronal de atención tuviera 101 pesos, serían posicionales y deben ser calculados por el \n",
    "#valor semántico de los nucleótidos (si fueran palabras por su significado, no por su posición)\n",
    "\n",
    "#Nuestra red neuronal de atención debe atender al \"significado\" de las palabras, es decir,\n",
    "#a la codificación de cada nucleótido en el vector de estados \n",
    "#de la LSTM que tiene dimensión 512. Por lo tanto el número de pesos de la  red de atención \n",
    "# es de (512,1). Son los pesos de las 512 conexiones de la neurona de esta capa.\n",
    "\n",
    "#Durante el entrenamiento multiplicaremos matricialmente todos los nucleótidos de la \n",
    "#secuencia (101), con su codificación LSTMbidi(512), por los pesos de la capa de atención(512) y eso \n",
    "#nos dará los 101 pesos de atención:\n",
    "#(101,512) x (512,1) = (101,1) los pesos de atención\n",
    "#(512,1) son los pesos de la capa.\n",
    "\n",
    "#Ahora entendemos por qué los pesos de atención no son constantes\n",
    "#sino que para cada secuencia cambian:\n",
    "#En una red ya entrenada:\n",
    "#  (101,512)[variable] x (512,1)[constante] = (101,1)[variable]\n",
    "\n",
    "#===============================================================\n",
    "\n",
    "#===============================\n",
    "#METHOD 2: using regular layers:\n",
    "#===============================\n",
    "\n",
    "#---------uncomment here--------------------\n",
    "e=Dense(1, activation='tanh')(dropout) #Capa de atención\n",
    "e=Flatten()(e)\n",
    "a=Activation('softmax')(e) #Softmax para que sumen 1 los pesos de atención.\n",
    "temp=RepeatVector(2*num_lstm_units)(a)\n",
    "temp=Permute([2, 1])(temp)\n",
    "# multiply weight with LSTM layer o/p\n",
    "output = Multiply()([dropout, temp])\n",
    "# Get the attention adjusted output state by adding up\n",
    "att = Lambda(lambda values: K.sum(values, axis=1))(output)\n",
    "#-----------------------------\n",
    "\n",
    "#===============================================================\n",
    "output_bias=initial_bias\n",
    "output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "outputs= layers.Dense(1, activation='sigmoid', bias_initializer=output_bias, name=\"OUTPUT\")(att)\n",
    "#Creamos el modelo\n",
    "model_from_scratch  = keras.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "\n",
    "#Mostramos el modelo\n",
    "print(model_from_scratch.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc47876-f37d-49b9-8927-208034317df9",
   "metadata": {
    "id": "ddc47876-f37d-49b9-8927-208034317df9"
   },
   "outputs": [],
   "source": [
    "#Compilation reset all weights\n",
    "model_from_scratch.compile(optimizer=keras.optimizers.Adam(),\n",
    "                           loss     =keras.losses.BinaryCrossentropy(),\n",
    "                           metrics  =[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "model=model_from_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9WyvcKhMJSEE",
   "metadata": {
    "id": "9WyvcKhMJSEE"
   },
   "source": [
    "Recover last model, best model or generate a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c51c7-f1ee-489b-b306-fbf948a07a51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1653155704289,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "643c51c7-f1ee-489b-b306-fbf948a07a51",
    "outputId": "bfae009b-2b57-45ee-a2e4-55798581e3b4"
   },
   "outputs": [],
   "source": [
    "#Load the trained model from disk\n",
    "import os.path\n",
    "\n",
    "best_model_accuracy =0\n",
    "last_model_accuracy =0\n",
    "\n",
    "if os.path.exists(bestmodelfile):\n",
    "    model = tf.keras.models.load_model(bestmodelfile)\n",
    "    print(\"Testing best model file: {}\".format(bestmodelfile))\n",
    "    results = model.evaluate(validation_generator,verbose=1)\n",
    "    best_model_accuracy = results[1]\n",
    "    print(\"best model accuracy: {}\".format(best_model_accuracy))    \n",
    "\n",
    "if os.path.exists(lastmodelfile):\n",
    "    model = tf.keras.models.load_model(lastmodelfile)\n",
    "    print(\"Testing last complete model file: {}\".format(lastmodelfile))\n",
    "    results = model.evaluate(validation_generator,verbose=1)\n",
    "    last_model_accuracy = results[1]\n",
    "    print(\"last model accuracy: {}\".format(last_model_accuracy))           \n",
    "\n",
    "\n",
    "if best_model_accuracy > last_model_accuracy:\n",
    "   model = tf.keras.models.load_model(bestmodelfile)\n",
    "   print(\"Selected best model saved: {}\".format(bestmodelfile))\n",
    "else:\n",
    "  if last_model_accuracy > best_model_accuracy:\n",
    "     print(\"Selected last model saved: {}\".format(lastmodelfile))\n",
    "  else:\n",
    "     print(\"Selected new untrained model\")\n",
    "\n",
    "\n",
    "# Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b1c7b-7c45-4483-88fc-e60a012edba0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1653155705481,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "644b1c7b-7c45-4483-88fc-e60a012edba0",
    "outputId": "fe276735-c288-4eee-ab6f-c3a5a284f02c"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d28828-8ee5-4bc6-8b97-1e06ab60c519",
   "metadata": {
    "id": "84d28828-8ee5-4bc6-8b97-1e06ab60c519"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(bestmodelfile, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1,\n",
    "                             save_best_only=True, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "\n",
    "callback=EarlyStopping(monitor='val_loss', \n",
    "                       min_delta=0, \n",
    "                       patience=3, \n",
    "                       verbose=1, \n",
    "                       mode='auto',\n",
    "                       baseline=None, \n",
    "                       restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571758b3-2bad-4d21-9796-725f4aa9ed9c",
   "metadata": {},
   "source": [
    "We will use always the same initial weights for results be comparable between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58848be-ed5e-45d4-9104-b11632efca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
    "model.save_weights(initial_weights)\n",
    "print(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8cf44-1537-4705-8364-802268d8db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22345410-c762-42e4-9767-5ef8b1edb003",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5697106,
     "status": "ok",
     "timestamp": 1653170653646,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "2c010059-0891-4e9e-b052-692596e89876",
    "outputId": "cdaea5a6-0834-49d0-973d-58f4b71749cd"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_name):#Use GPU if available\n",
    "    history=model.fit(training_generator,epochs=n_epochs,\n",
    "                      validation_data=validation_generator,\n",
    "                      callbacks=[checkpoint,callback],\n",
    "                      class_weight=class_weight,\n",
    "                      verbose=trace_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edd824-ea63-46fa-a917-5e41dbd3422c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1653170653647,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "c8edd824-ea63-46fa-a917-5e41dbd3422c",
    "outputId": "c8d69b95-70b0-49bb-bfbe-d797f79aef2e"
   },
   "outputs": [],
   "source": [
    "#We always save the last model.\n",
    "#Last model can be triggered by early stopping\n",
    "n_epochs_trained = len(history.history['loss'])\n",
    "print(\"Trained epochs: {} of {}\".format(n_epochs_trained,n_epochs))\n",
    "model.save(lastmodelfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb710-78e7-4734-b41f-eccd0a9ff589",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1653170654209,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "634fb710-78e7-4734-b41f-eccd0a9ff589",
    "outputId": "4f67a633-f93e-4cfe-c29d-6a8bfc4c86e2"
   },
   "outputs": [],
   "source": [
    "#PLOT ACCURACY AND LOSS\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366e2cf-105b-4007-8732-9c3f330f9cb2",
   "metadata": {
    "id": "c366e2cf-105b-4007-8732-9c3f330f9cb2",
    "outputId": "c72777c6-5a20-481f-c89e-89ed00121599"
   },
   "source": [
    "We recover the best model saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657a2d3-548a-4475-a171-831406ed1140",
   "metadata": {
    "id": "d657a2d3-548a-4475-a171-831406ed1140"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(bestmodelfile):\n",
    "    model = tf.keras.models.load_model(bestmodelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11909c-fe48-433d-a1ab-b038b301bc16",
   "metadata": {
    "id": "4a11909c-fe48-433d-a1ab-b038b301bc16",
    "outputId": "c72777c6-5a20-481f-c89e-89ed00121599"
   },
   "source": [
    "We evaluate the best model on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae3e40-6872-49cd-95c2-91b624ee4193",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 120776,
     "status": "ok",
     "timestamp": 1653170776111,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "4bae3e40-6872-49cd-95c2-91b624ee4193",
    "outputId": "f490674a-ee81-4ac2-9f83-d38625e79105"
   },
   "outputs": [],
   "source": [
    "#EVALUATE VALIDATION DATASET\n",
    "print(\"Evaluate models on validation data\")\n",
    "results_model = model.evaluate(validation_generator,verbose=trace_level)\n",
    "print ('Accuracy on validation data:',round(results_model[1],3))\n",
    "print ('Loss on validation data:',round(results_model[0],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81704c88-897a-4f89-b1f5-80f6a5f3d364",
   "metadata": {
    "id": "81704c88-897a-4f89-b1f5-80f6a5f3d364",
    "outputId": "205c012b-84d2-4f51-c96a-398417f7e61f"
   },
   "source": [
    "We make predictions on test data, never used during training nor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7abf2c-e423-485d-a543-06f4743971c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246983,
     "status": "ok",
     "timestamp": 1653172115150,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "fb7abf2c-e423-485d-a543-06f4743971c7",
    "outputId": "86dc918c-36bf-4c59-a71c-779a4e86f898"
   },
   "outputs": [],
   "source": [
    "#PREDICTIONS\n",
    "print(\"Make predictions on test data\")\n",
    "model_prediction = model.predict(test_generator,verbose=trace_level)\n",
    "model_prediction_binary = (model_prediction > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08289e1-32e4-4290-82c7-b87718f230a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1653172124025,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "d08289e1-32e4-4290-82c7-b87718f230a9",
    "outputId": "b2e91ab3-a67d-4bb7-ce3d-7e557bb27ce3"
   },
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(model_prediction.shape)\n",
    "print(model_prediction_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9296b0f-efc6-4133-aaff-949a4159e5f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1653172134177,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "a9296b0f-efc6-4133-aaff-949a4159e5f7",
    "outputId": "6997f965-de01-4748-b4c3-c11717fd1b36"
   },
   "outputs": [],
   "source": [
    "#METRICS QUALITY CLASSIFICATION\n",
    "print(\"MODEL \"+model_name+\"\\n---------------------------------\")\n",
    "kappa = cohen_kappa_score(y_test, model_prediction_binary)\n",
    "print ('Kappa:',round(kappa,3))\n",
    "print(classification_report(y_test, model_prediction_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f01e9-daf3-43f6-bd2f-d1fee30059cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1653172156103,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "686f01e9-daf3-43f6-bd2f-d1fee30059cb",
    "outputId": "0c00e40c-c08e-423b-a600-3f14672fb347"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, cohen_kappa_score, classification_report\n",
    "import seaborn as sns; sns.set()\n",
    "# PLOT CONFUSION MATRIX\n",
    "# Tutorial: https://www.stackvidhya.com/plot-confusion-matrix-in-python-and-why/\n",
    "plt.figure()\n",
    "\n",
    "cm = confusion_matrix(data_y_test,model_prediction_binary)\n",
    "\n",
    "group_names = ['TN','FP','FN','TP']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "ax.set_title('RNA-Editing Confusion Matrix \\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values '+ model_name)\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "#ax.xaxis.set_ticklabels(['False','True'])\n",
    "#ax.yaxis.set_ticklabels(['False','True'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff605a-c7fd-4160-ba29-a2e88cd1829e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1653172211233,
     "user": {
      "displayName": "Jesús Peñuela",
      "userId": "04868940139927239067"
     },
     "user_tz": -120
    },
    "id": "c1ff605a-c7fd-4160-ba29-a2e88cd1829e",
    "outputId": "3790b74d-a777-41e3-aeb9-24dcae687c57"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "    plt.plot([0, 1], [0, 1], color=\"darkblue\", linestyle=\"--\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_test, model_prediction)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model_prediction)\n",
    "plot_roc_curve(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b11f17-ec6e-481d-8e66-11fe54067d5e",
   "metadata": {},
   "source": [
    "# RESULTS INSIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488a42e-0fbb-4dfd-a445-2071460f1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = data_test\n",
    "if 'RESULT_TYPE' not in results_data.columns:\n",
    "    #insert column at position 3\n",
    "    results_data.insert(3,\"RESULT_TYPE\", None)\n",
    "    results_data.insert(4,\"PROB_PRED\",model_prediction)\n",
    "else:\n",
    "    print(\"RESULT_TYPE already exists in the dataframe\")\n",
    "\n",
    "results_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21582e-b831-439b-9274-b6d207cf1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_index=results_data.columns.get_loc('RESULT_TYPE')\n",
    "i=0\n",
    "for result in model_prediction_binary:\n",
    "    #print(\"Comparing result={} with data_y_test={}\".format(result[0],data_y_test.iloc[i]))\n",
    "    if   result[0]==0 and data_y_test.iloc[i]==0:\n",
    "       typeRes =\"TN\"\n",
    "    elif result[0]==0 and data_y_test.iloc[i]==1:\n",
    "       typeRes=\"FN\"\n",
    "    elif result[0]==1 and data_y_test.iloc[i]==0:\n",
    "       typeRes=\"FP\"\n",
    "    elif result[0]==1 and data_y_test.iloc[i]==1:\n",
    "       typeRes=\"TP\"\n",
    "    results_data.iloc[i, column_index]=typeRes\n",
    "    i+=1\n",
    "    \n",
    "results_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a349bb-be4e-4592-8829-38c57f3d227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results into a file\n",
    "report_dir=\"/content/drive/MyDrive/REPORT\"\n",
    "results_csv_file  =model_name + \"_Results.csv\"\n",
    "results_excel_file=model_name + \"_Results.xlsx\"\n",
    "results_data.to_csv(os.path.join(report_dir,results_csv_file))\n",
    "results_data.to_excel(os.path.join(report_dir,results_excel_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba0511-b3c1-4c0c-9981-e9c8fb3a7f10",
   "metadata": {},
   "source": [
    "Now, we are going to find the record with highest probability and category TP (True Positive) as a good model of TP data,\n",
    "and alternatively, the best representative of TN, using the lowest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e9e02-9205-4337-b1c9-2eef3abdfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_TP=results_data.loc[results_data['RESULT_TYPE'] == 'TP']\n",
    "prototype_of_TP_id=subset_TP['PROB_PRED'].idxmax()\n",
    "print(\"rowid best TP = {}\".format(prototype_of_TP_id))\n",
    "print(results_data.loc[prototype_of_TP_id,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c57852d-ee68-4dd5-a7bd-ff813b84f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_TN=results_data.loc[results_data['RESULT_TYPE'] == 'TN']\n",
    "prototype_of_TN_id=subset_TN['PROB_PRED'].idxmin()\n",
    "print(\"rowid best TN = {}\".format(prototype_of_TN_id))\n",
    "print(results_data.loc[prototype_of_TN_id,])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "TFM_LSTMBidiAttention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
